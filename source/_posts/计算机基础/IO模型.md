---
title: IO模型
date: 2023-03-26 16:51:33
tags: 
- IO模型
- 操作系统
categories:
- 计算机基础
---

# 前言

经常在网上看到各种IO，比如阻塞/非阻塞IO、同步/异步IO、IO多路复用，又比如select、poll、epoll、reactor。以及BIO、NIO、AIO等概念。

被这些概念给迷花了眼，因此一怒之下决心搞清这些东西

# 什么是IO

I/O 的全称是Input/Output。虽常谈及I/O，但想必你也一时不能给出一个完整的定义。搜索了谷歌，发现也尽是些冗长的论述。要想厘清I/O这个概念，我们需要从不同的视角去理解它。

## 计算机的IO

我们常说的输入输出，比较直观的意思就是**计算机的输入输出**，**计算机就是主体**。大家是否还记得，大学学**计算机组成原理**的时候，有个**冯.诺依曼结构**，它将计算机分成分为5个部分：运算器、控制器、存储器、输入设备、输出设备。

![image-20230326195605212](https://yumoimgbed.oss-cn-shenzhen.aliyuncs.com/img/image-20230326195605212.png)

输入设备是向计算机输入数据和信息的设备，键盘，鼠标都属于输入设备；输出设备是计算机硬件系统的终端设备，用于接收计算机数据的输出显示，一般显示器、打印机属于输出设备。

> 例如你在鼠标键盘敲几下，它就会把你的指令数据，传给主机，主机通过运算后，把返回的数据信息，输出到显示器。

鼠标、显示器这只是直观表面的输入输出，回到计算机架构来说，**涉及计算机核心与其他设备间数据迁移的过程，就是IO**。如磁盘IO，就是从磁盘读取数据到内存，这算一次输入，对应的，将内存中的数据写入磁盘，就算输出。这就是IO的本质。

## 操作系统的IO

我们要将内存中的数据写入到磁盘的话，主体会是什么呢？主体可能是一个应用程序，比如一个Java进程（假设网络传来二进制流，一个Java进程可以把它写入到磁盘）。

**操作系统**负责计算机的资源管理和进程的调度。我们电脑上跑着的应用程序，其实是需要经过**操作系统**，才能做一下特殊操作，如**磁盘文件读写、内存的读写**等等。因为这些都是比较危险的操作，不可以由应用程序乱来，只能交给底层操作系统来。也就是说，你的应用程序要把数据写入磁盘，只能通过调用操作系统开放出来的API来操作。

> - 什么是用户空间？什么是内核空间?
> - 以32位操作系统为例，它为每一个进程都分配了4G(2的32次方)的内存空间。这4G可访问的内存空间分为二部分，一部分是用户空间，一部分是内核空间。内核空间是操作系统内核访问的区域，是受保护的内存空间，而用户空间是用户应用程序访问的内存区域。

我们应用程序是跑在用户空间的，它不存在实质的IO过程，真正的IO是在**操作系统**执行的。即应用程序的IO操作分为两种动作：**IO调用和IO执行**。IO调用是由进程（应用程序的运行态）发起，而IO执行是**操作系统内核**的工作。此时所说的IO是应用程序对操作系统IO功能的一次触发，即IO调用。

### 操作系统的一次IO过程

应用程序发起的一次IO操作包含两个阶段：

- IO调用：应用程序进程向操作系统**内核**发起调用。
- IO执行：操作系统内核完成IO操作。

操作系统内核完成IO操作还包括连个两个过程：

- 准备数据阶段：内核等待I/O设备准备好数据
- 拷贝数据阶段：将数据从内核缓冲区拷贝到用户空间缓冲区

![image-20230326195729181](https://yumoimgbed.oss-cn-shenzhen.aliyuncs.com/img/image-20230326195729181.png)

其实IO不就是把进程的内部数据转移到外部设备，或者把外部设备的数据迁移到进程内部。外部设备一般指硬盘、socket通讯的网卡。一个完整的**IO过程**包括以下几个步骤：

- 应用程序进程向操作系统发起**IO调用请求**
- 操作系统**准备数据**，把IO外部设备的数据，加载到**内核缓冲区**
- 操作系统拷贝数据，即将内核缓冲区的数据，拷贝到进程缓冲区

# TCP发送数据的流程

要深入的理解各种IO模型，那么必须先了解下产生各种IO的原因是什么，要知道这其中的本质问题那么我们就必须要知道一条消息是如何从一个人发送到另外一个人的；

以两个应用程序通讯为例，我们来了解一下当“A”向"B" 发送一条消息，简单来说会经过如下流程：

1. 应用A把消息发送到 TCP发送缓冲区。
2. TCP发送缓冲区再把消息发送出去，经过网络传递后，消息会发送到B服务器的TCP接收缓冲区。
3. B再从TCP接收缓冲区去读取属于自己的数据。

![image-20230326203448609](https://yumoimgbed.oss-cn-shenzhen.aliyuncs.com/img/image-20230326203448609.png)

我们把视角切换到上面图中的第三步， 也就是应用B从TCP缓冲区中读取数据

**思考一个问题：**

因为应用之间发送消息是间断性的，也就是说在上图中TCP缓冲区还没有接收到属于应用B该读取的消息时，那么此时应用B向TCP缓冲区发起读取申请，TCP接收缓冲区是应该马上告诉应用B 现在没有你的数据，还是说让应用B在这里等着，直到有数据再把数据交给应用B。

把这个问题应用到第一个步骤也是一样，应用A在向TCP发送缓冲区发送数据时，如果TCP发送缓冲区已经满了，那么是告诉应用A现在没空间了，还是让应用A等待着，等TCP发送缓冲区有空间了再把应用A的数据访拷贝到发送缓冲区。

# 阻塞IO模型(BIO)

如果上面的问题你已经思考过了，那么其实你已经明白了什么是阻塞IO了，所谓阻塞IO就是当应用B发起读取数据申请时，在内核数据没有准备好之前，应用B会一直处于等待数据状态，直到内核把数据准备好了交给应用B才结束。

**术语描述**：在应用调用recvfrom读取数据时，其系统调用直到数据包到达且被复制到应用缓冲区中或者发送错误时才返回，在此期间一直会等待，进程从调用到返回这段时间内都是被阻塞的称为阻塞IO；

应用程序中进程在发起IO调用后至内核执行IO操作返回结果之前，若发起系统调用的线程一直处于等待状态，则此次IO操作为阻塞IO。阻塞IO简称BIO，Blocking IO。其处理流程如下图所示：

![image-20230326195906164](https://yumoimgbed.oss-cn-shenzhen.aliyuncs.com/img/image-20230326195906164.png)


1、应用进程向内核发起recfrom读取数据。

2、准备数据报（应用进程阻塞）。

3、将数据从内核负责到应用空间。

4、复制完成后，返回成功提示。

从上图可知当用户进程发起IO系统调用后，内核从准备数据到拷贝数据到用户空间的两个阶段期间用户调用线程选择**阻塞**等待数据返回。

- 阻塞IO比较经典的应用就是**阻塞socket、Java BIO**。
- 阻塞IO的缺点就是：如果内核数据一直没准备好，那用户进程将一直阻塞，**浪费性能**，可以使用**非阻塞IO**优化。

# 非阻塞IO模型(NIO)

按照上面的思路，所谓非阻塞IO就是当应用B发起读取数据申请时，如果内核数据没有准备好会即刻告诉应用B，不会让B在这里等待。

**术语**：非阻塞IO是在应用调用recvfrom读取数据时，如果该缓冲区没有数据的话，就会直接返回一个EWOULDBLOCK错误，不会让应用一直等待中。在没有数据的时候会即刻返回错误标识，那也意味着如果应用要读取数据就需要不断的调用recvfrom请求，直到读取到它数据要的数据为止。

如果内核数据还没准备好，可以先返回错误信息给用户进程，让它不需要等待，而是通过**轮询**的方式再来请求。这就是非阻塞IO，流程图如下：

![image-20230326200052614](https://yumoimgbed.oss-cn-shenzhen.aliyuncs.com/img/image-20230326200052614.png)

非阻塞IO的流程如下：

- 应用进程向操作系统内核，发起`recvfrom`读取数据。
- 操作系统内核数据没有准备好，立即返回`EWOULDBLOCK`错误码。
- 应用程序轮询调用，继续向操作系统内核发起`recvfrom`读取数据。
- 操作系统内核数据准备好了，从内核缓冲区拷贝到用户空间。
- 完成调用，返回成功提示。

非阻塞IO模型，简称**NIO**，`Non-Blocking IO`。它相对于阻塞IO，虽然大幅提升了性能，但是它依然存在**性能问题**，即**频繁的轮询**，导致频繁的系统调用，同样会消耗大量的CPU资源。

**NIO问题的本质就是频繁轮询导致的无效系统调用**。可以考虑**IO复用模型**，去解决这个问题。

# IO多路复用模型

既然**NIO**无效的轮询会导致CPU资源消耗，我们等到内核数据准备好了，主动通知应用进程再去进行系统调用不就好了嘛？

我们还是把视角放到应用B从TCP缓冲区中读取数据这个环节来。如果在并发的环境下，可能会N个人向应用B发送消息，这种情况下我们的应用就必须创建多个线程去读取数据，每个线程都会自己调用recvfrom 去读取数据。那么此时情况可能如下图：

![img](https://yumoimgbed.oss-cn-shenzhen.aliyuncs.com/img/v2-529734ac694c4da96ac78eeebd7deb6b_720w.webp)



如上图一样，并发情况下服务器很可能一瞬间会收到几十上百万的请求，这种情况下应用B就需要创建几十上百万的线程去读取数据，同时又因为应用线程是不知道什么时候会有数据读取，为了保证消息能及时读取到，那么这些线程自己必须不断的向内核发送recvfrom 请求来读取数据；

那么问题来了，这么多的线程不断调用recvfrom 请求数据，先不说服务器能不能扛得住这么多线程，就算扛得住那么很明显这种方式是不是太浪费资源了，线程是我们操作系统的宝贵资源，大量的线程用来去读取数据了，那么就意味着能做其它事情的线程就会少。

所以，有人就提出了一个思路，能不能提供一种方式，可以由一个线程监控多个网络请求（**我们后面将称为fd文件描述符，linux系统把所有网络请求以一个fd来标识**），这样就可以只需要一个或几个线程就可以完成数据状态询问的操作，当有数据准备就绪之后再分配对应的线程去读取数据，这么做就可以节省出大量的线程资源出来，这个就是IO复用模型的思路。

> **文件描述符fd**(File Descriptor)：它是计算机科学中的一个术语，形式上是一个非负整数。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。

![img](https://yumoimgbed.oss-cn-shenzhen.aliyuncs.com/img/v2-2c65fd3534e58d3a54cdeae778a31446_720w.webp)

正如上图，IO复用模型核心思路：系统给我们提供**一类函数**（如**select、poll、epoll**函数），它们可以同时监控多个`fd`的操作，任何一个返回内核数据就绪，应用进程再发起`recvfrom`系统调用。

## select

应用进程通过调用select函数，可以同时监控多个`fd`，在`select`函数监控的`fd`中，只要有任何一个数据状态准备就绪了，`select`函数就会返回可读状态，这时应用进程再发起`recvfrom`请求去读取数据。

![image-20230326200557214](https://yumoimgbed.oss-cn-shenzhen.aliyuncs.com/img/image-20230326200557214.png)

非阻塞IO模型（NIO）中，需要`N`（N>=1）次轮询系统调用，然而借助`select`的IO多路复用模型，只需要发起一次系统调用就够了,大大优化了性能。

但是呢，`select`有几个缺点：

- 监听的IO最大连接数有限，在Linux系统上一般为1024。
- select函数返回后，是通过遍历`fdset`，找到就绪的描述符`fd`。（仅知道有I/O事件发生，却不知是哪几个流，所以遍历所有流）

因为**存在连接数限制**，所以后来又提出了**poll**。与select相比，**poll**解决了**连接数限制问题**。但是呢，select和poll一样，还是需要通过遍历文件描述符来获取已经就绪的`socket`。如果同时连接的大量客户端在一时刻可能只有极少处于就绪状态，伴随着监视的描述符数量的增长，**效率也会线性下降**。

因此经典的多路复用模型`epoll`诞生。

## epoll

针对select/pool引入的问题，我们把解决问题的思路转回到内核上，如何减少内核重复无效的循环遍历呢？变主动为被动，基于事件驱动来实现。其流程图如下所示：

![image-20230326200725514](https://yumoimgbed.oss-cn-shenzhen.aliyuncs.com/img/image-20230326200725514.png)

**epoll**先通过`epoll_ctl()`来注册一个`fd`（文件描述符），一旦基于某个`fd`就绪时，内核会采用回调机制，迅速激活这个`fd`，当进程调用`epoll_wait()`时便得到通知。这里去掉了**遍历文件描述符**的操作，而是采用**监听事件回调**的的机制。这就是epoll的亮点。

epoll本质上是一种**同步非阻塞IO**

## **select、poll、epoll的区别**

|              | select                                               | poll                                               | epoll                                                        |
| ------------ | ---------------------------------------------------- | -------------------------------------------------- | ------------------------------------------------------------ |
| 底层数据结构 | 数组                                                 | 链表                                               | 红黑树和双链表                                               |
| 获取就绪的fd | 遍历                                                 | 遍历                                               | 事件回调                                                     |
| 事件复杂度   | O(n)                                                 | O(n)                                               | O(1)                                                         |
| 最大连接数   | 1024                                                 | 无限制                                             | 无限制                                                       |
| fd数据拷贝   | 每次调用select，需要将fd数据从用户空间拷贝到内核空间 | 每次调用poll，需要将fd数据从用户空间拷贝到内核空间 | 使用内存映射(mmap)，不需要从用户空间频繁拷贝fd数据到内核空间 |

**epoll**明显优化了IO的执行效率，但在IO执行的第一阶段：在进程调用`epoll_wait()`即数据准备阶段都还是被阻塞的。所以这是一个可以继续优化的点。

**总结：**复用IO的基本思路就是通过select或poll、epoll 来监控多fd ，来达到不必为每个fd创建一个对应的监控线程，从而减少线程资源创建的目的。

有关这三种IO复用模型的具体实现可看[答应我，这次一定要搞懂IO多路复用 - 掘金 (juejin.cn)](https://juejin.cn/post/7195371358144954428)

# 信号驱动模型

信号驱动IO与BIO和NIO最大的区别就在于，在IO执行的数据准备阶段，不会阻塞用户进程。

![img](https://yumoimgbed.oss-cn-shenzhen.aliyuncs.com/img/v2-2461c8df6a154930afb4e7c345442835_720w.webp)

信号驱动IO不再用主动询问的方式去确认数据是否就绪，而是向内核发送一个信号（调用`sigaction`的时候建立一个`SIGIO`的信号），然后应用用户进程可以去做别的事，不用阻塞。当内核数据准备好后，再通过`SIGIO`信号通知应用进程，数据准备好后的可读状态。应用用户进程收到信号之后，立即调用`recvfrom`，去读取数据。

![image-20230326201100031](https://yumoimgbed.oss-cn-shenzhen.aliyuncs.com/img/image-20230326201100031.png)

乍一看，信号驱动式I/O模型有种异步操作的感觉，但是在IO执行的第二阶段，也就是将数据从内核空间复制到用户空间这个阶段，用户进程还是被阻塞的。

回过头来看下，不管是BIO，还是NIO，还是信号驱动，在数据从内核复制到应用缓冲的时候，都是阻塞的。还有没有优化方案呢？**AIO**（真正的异步IO）！

# 异步IO模型(AIO)

![img](https://yumoimgbed.oss-cn-shenzhen.aliyuncs.com/img/v2-96009f54d89ade0d8c4001bc67395c57_720w.webp)

异步IO真正实现了IO全流程的非阻塞。用户进程发出系统调用后立即返回，内核等待数据准备完成，然后将数据拷贝到用户进程缓冲区，然后发送信号告诉用户进程**IO操作执行完毕**（与SIGIO相比，一个是发送信号告诉用户进程数据准备完毕，一个是IO执行完毕）。其流程如下：

![image-20230326201256579](https://yumoimgbed.oss-cn-shenzhen.aliyuncs.com/img/image-20230326201256579.png)

异步IO的优化思路很简单，只需要向内核发送一次请求，就可以完成数据状态询问和数据拷贝的所有操作，并且不用阻塞等待结果。

# 阻塞、非阻塞、同步、异步IO划分

![image-20230326201346597](https://yumoimgbed.oss-cn-shenzhen.aliyuncs.com/img/image-20230326201346597.png)

![image-20230326193424313](https://yumoimgbed.oss-cn-shenzhen.aliyuncs.com/img/image-20230326193424313.png)

## **再谈IO模型里面的同步异步**

我们通常会说到同步阻塞IO、同步非阻塞IO，异步IO几种术语，通过上面的内容，那么我想你现在肯定已经理解了什么是阻塞什么是非阻塞了，所谓阻塞就是**发起读取数据请求的时，当数据还没准备就绪的时候**，这时请求是即刻返回，还是在这里等待数据的就绪，如果需要等待的话就是阻塞，反之如果即刻返回就是非阻塞。



我们区分了阻塞和非阻塞后再来分别下同步和异步，在IO模型里面如果请求方从发起请求到数据最后完成的这一段过程中都需要自己参与，那么这种我们就称为同步请求；反之，如果应用发送完指令后就不再参与过程了，只需要等待最终完成结果的通知，那么这就属于异步。



我们再看同步阻塞、同步非阻塞，他们不同的只是发起读取请求的时候一个请求阻塞，一个请求不阻塞，但是相同的是，他们都需要应用自己监控整个数据完成的过程。而为什么只有异步非阻塞 而没有异步阻塞呢，因为异步模型下请求指定发送完后就即刻返回了，没有任何后续流程了，所以它注定不会阻塞，所以也就只会有异步非阻塞模型了。

> **参考**
>
> [看一遍就理解：IO模型详解 - 掘金 (juejin.cn)](https://juejin.cn/post/7036518015462015006#heading-2)
>
> [IO 模型知多少 | 理论篇 - 腾讯云开发者社区-腾讯云 (tencent.com)](https://cloud.tencent.com/developer/article/1648650)
>
> [答应我，这次一定要搞懂IO多路复用 - 掘金 (juejin.cn)](https://juejin.cn/post/7195371358144954428#heading-1)
>
> [100%弄明白5种IO模型 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/115912936)